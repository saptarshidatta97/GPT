"# GPT" 

Self Attention

![Self Attention](artifacts/selfattention.png)

Causal Attention

![Causal Attention](artifacts/causalattention.png)

Causal Attention with Dropout

![causal Attention with Dropout](artifacts/causalattentionwithdropout.png)

Multi Head Attention with Multiple causal Heads stacked on top of each other

![Multi Head Attention](artifacts/multiheadattention_v1.png)

Multi Head Attention with Weight Splits

![Multi Head Attention with Weight Splits](artifacts/multiheadattention_v2.png)

Layer Normalization

![Layer Normalization](artifacts/layernorm.png)

GELU v/s RELU

![GELU](artifacts/gelu.png)

Feed Forward Network

![Feed Forward](artifacts/feedforward.png)

Transformer Architecture

![Transformmer Architecture](artifacts/transformer.png)